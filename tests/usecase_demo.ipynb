{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a07a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Debugging with __repr__\n",
      "Before fit: LinearModel(add_intercept=True, not fitted)\n",
      "After fit: LinearModel(n_features=4, n_obs=100, fitted)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Real-world examples of dunder method usage.\n",
    "Demonstrates practical, non-academic applications.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from EasyLM import LinearModel, ModelComparator\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.randn(n, 3)\n",
    "y = 5 + 2*X[:, 0] - 3*X[:, 1] + 1.5*X[:, 2] + np.random.randn(n)*0.5\n",
    "\n",
    "\n",
    "# 1. __repr__: Debugging model state\n",
    "print(\"\\n1. Debugging with __repr__\")\n",
    "\n",
    "model = LinearModel()\n",
    "print(\"Before fit:\", repr(model))\n",
    "\n",
    "model.fit(X, y)\n",
    "print(\"After fit:\", repr(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56df54d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Model summary with __str__\n",
      "LinearModel: 4 parameters, 100 observations, RÂ²=0.9874\n"
     ]
    }
   ],
   "source": [
    "# 2. __str__: User-friendly summary\n",
    "print(\"\\n2. Model summary with __str__\")\n",
    "print(str(model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a932f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Compare model equality with __eq__\n",
      "Equal models (same data): True\n",
      "Equal models (different data): False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. __eq__: Checking model equality\n",
    "print(\"\\n3. Compare model equality with __eq__\")\n",
    "\n",
    "model_v1 = LinearModel()\n",
    "model_v1.fit(X, y)\n",
    "\n",
    "model_v2 = LinearModel()\n",
    "model_v2.fit(X, y)\n",
    "\n",
    "print(\"Equal models (same data):\", model_v1 == model_v2)\n",
    "\n",
    "model_v3 = LinearModel()\n",
    "model_v3.fit(X[:80], y[:80])\n",
    "print(\"Equal models (different data):\", model_v1 == model_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae214d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Ranking models using __lt__\n",
      "Ranked by AIC:\n",
      "1 Model_3_features AIC= -158.4999134248202\n",
      "2 Model_2_features AIC= 104.32727599034547\n",
      "3 Model_1_features AIC= 257.39912138059924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 4. __lt__: Ranking models by AIC\n",
    "print(\"\\n4. Ranking models using __lt__\")\n",
    "\n",
    "models = []\n",
    "for i in range(1, 4):\n",
    "    m = LinearModel()\n",
    "    m.fit(X[:, :i], y)\n",
    "    m.name = f\"Model_{i}_features\"\n",
    "    models.append(m)\n",
    "\n",
    "ranked = sorted(models)\n",
    "\n",
    "print(\"Ranked by AIC:\")\n",
    "for i, m in enumerate(ranked, 1):\n",
    "    print(i, m.name, \"AIC=\", m.aic())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511856e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Using __len__ to check training sample size\n",
      "Training samples: 100\n",
      "Sample size is sufficient\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. __len__: Checking sample size\n",
    "print(\"\\n5. Using __len__ to check training sample size\")\n",
    "\n",
    "print(\"Training samples:\", len(model))\n",
    "\n",
    "MIN_SAMPLES = 50\n",
    "if len(model) >= MIN_SAMPLES:\n",
    "    print(\"Sample size is sufficient\")\n",
    "else:\n",
    "    print(\"Sample size is below recommended minimum\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a13030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Accessing coefficients with __getitem__\n",
      "Intercept: 5.056431145685861\n",
      "Feature_1: 1.9611683569080296\n",
      "Feature_2: -3.0249817753601973\n",
      "Feature_3: 1.4462033429169872\n",
      "Most important feature: Feature_2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. __getitem__: Accessing coefficients\n",
    "print(\"\\n6. Accessing coefficients with __getitem__\")\n",
    "\n",
    "feature_names = [\"Feature_1\", \"Feature_2\", \"Feature_3\"]\n",
    "\n",
    "print(\"Intercept:\", model[0])\n",
    "for i, name in enumerate(feature_names, 1):\n",
    "    print(name + \":\", model[i])\n",
    "\n",
    "coefs = [abs(model[i]) for i in range(1, 4)]\n",
    "most_important = np.argmax(coefs) + 1\n",
    "print(\"Most important feature:\", feature_names[most_important - 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92e39a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. ModelComparator usage\n",
      "Total models: 3\n",
      "0 Model_1_features\n",
      "1 Model_2_features\n",
      "2 Model_3_features\n",
      "Model Comparison (3 models):\n",
      "                         aic         bic  r_squared  n_params  n_obs\n",
      "model                                                               \n",
      "Model_1_features  257.399121  262.609462   0.161748         2    100\n",
      "Model_2_features  104.327276  112.142787   0.822210         3    100\n",
      "Model_3_features -158.499913 -148.079233   0.987417         4    100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. Comparing multiple models with ModelComparator\n",
    "print(\"\\n7. ModelComparator usage\")\n",
    "\n",
    "comp = ModelComparator(models)\n",
    "\n",
    "print(\"Total models:\", len(comp))\n",
    "for i in range(len(comp)):\n",
    "    print(i, comp[i].name)\n",
    "\n",
    "print(str(comp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648af7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. Property examples\n",
      "Parameters: [ 5.05643115  1.96116836 -3.02498178  1.44620334]\n",
      "Observations: 100\n",
      "Features: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Using properties for safe attribute access\n",
    "print(\"\\n8. Property examples\")\n",
    "\n",
    "print(\"Parameters:\", model.params)\n",
    "print(\"Observations:\", model.n_obs)\n",
    "print(\"Features:\", model.n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19313d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. Production model selection example\n",
      "Selected model: complex\n",
      "R2: 0.987417224051415\n",
      "AIC: -158.4999134248202\n",
      "Samples: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 9. Production-like model selection (AIC-based)\n",
    "print(\"\\n9. Production model selection example\")\n",
    "\n",
    "candidates = {\n",
    "    \"simple\": LinearModel(),\n",
    "    \"standard\": LinearModel(),\n",
    "    \"complex\": LinearModel()\n",
    "}\n",
    "\n",
    "candidates[\"simple\"].fit(X[:, :1], y)\n",
    "candidates[\"standard\"].fit(X[:, :2], y)\n",
    "candidates[\"complex\"].fit(X, y)\n",
    "\n",
    "best_name = min(candidates, key=lambda k: candidates[k].aic())\n",
    "best_model = candidates[best_name]\n",
    "\n",
    "print(\"Selected model:\", best_name)\n",
    "print(\"R2:\", best_model.r_squared())\n",
    "print(\"AIC:\", best_model.aic())\n",
    "print(\"Samples:\", len(best_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c740ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10. Checking model persistence with __eq__\n",
      "Loaded model matches original\n",
      "\n",
      "All examples completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 10. Persistence check\n",
    "print(\"\\n10. Checking model persistence with __eq__\")\n",
    "\n",
    "original = LinearModel()\n",
    "original.fit(X, y)\n",
    "\n",
    "loaded = LinearModel()\n",
    "loaded.fit(X, y)\n",
    "\n",
    "if original == loaded:\n",
    "    print(\"Loaded model matches original\")\n",
    "else:\n",
    "    print(\"Mismatch detected\")\n",
    "\n",
    "\n",
    "print(\"\\nAll examples completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
